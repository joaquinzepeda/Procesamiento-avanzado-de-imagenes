# -*- coding: utf-8 -*-
"""Tarea4_imagenes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13eURgrzxIg5wa-p12DjdpVgVeN63R8R8

# Desarrollo por Joaquin Zepeda V.

Tarea 3 EL7008 - Detecci√≥n de personas usando Adaboost y caracter√≠sticas de tipo Haar.

# Subimos las imagenes a google colab y luego las extraemos

Se debe subir la archivo imagenes_tarea4_2022.zip y luego se ejecuta todo.
"""

!unzip /content/imagenes_tarea4_2022.zip

from sklearn.model_selection import train_test_split
import numpy as np
import cython
import cv2

np.random.seed(42)

"""
1. leer las im√°genes de la base de datos: 80% train, 20% test.  Para dividir los datos en
entrenamiento y prueba, se debe utilizar una semilla fija al usar train_test_split( )
Redimensionar las imagenes a 24x24.
Las etiquetas deben ser +1 para las imagenes con perosnas y -1 para las imagenes sin personas.
"""
import glob

def cargarDatos(nombre_carpeta,extension,clase):
    """
    Ejemplo de uso cargarDatos(car_side,"jpg",-1)
    """
    data = []
    path = glob.glob(f"{nombre_carpeta}//*.{extension}")
    if nombre_carpeta == "pedestrian":
        path.sort(key=lambda x: int((x.split(".")[0].split('/')[1]))) # ordena el conjunto de datos para tener resultados reproducibles
    else:
        path.sort(key=lambda x: int((x.split(".")[0].split('/')[1].split("_")[1]))) # ordena el conjunto de datos
    label = []
    for img in path:
        #leemos la imagen en escala de grises
        gray = cv2.imread(img,0)
        gray32 = np.float32(gray)
        out = cv2.resize(gray32, (24,24))
        data.append(out)
        label.append(clase)

    return np.array(data),np.array(label)


#Carga todos los datos de la carpeta "car_side" y le asigna la clase -1
dataCar_side,CSlabel = cargarDatos("car_side","jpg",-1)
text_labels = ["Cars/Chairs","pedestrian"]

#Carga todos los datos de la carpeta "chair" y le asigna la clase -1
dataChair,CL = cargarDatos("chair","jpg",-1)

#Carga todos los datos de la carpeta "pedestrian" y le asigna la clase 1
dataPedestrian,PL = cargarDatos("pedestrian","png",1)

#data no normalizada
data = np.concatenate((dataCar_side,dataChair,dataPedestrian))
labels = np.concatenate((CSlabel,CL,PL))

# Conjuntos de train y test
#random_state = 42 semilla fija para resultados reproducibles.
X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, shuffle = True, stratify = labels,random_state=42)

print(X_train.shape)
print(X_test.shape)

# Commented out IPython magic to ensure Python compatibility.
# %load_ext Cython

# Commented out IPython magic to ensure Python compatibility.
# %%cython
# 
# import numpy as np
# cimport numpy as np
# 
# cpdef np.ndarray[np.float32_t,ndim=2] integral(np.ndarray[np.float32_t,ndim=2] img):
#     """
#     2. funci√≥n en Cython que permita calcular la imagen integral, dada una imagen.
#     """
#     cdef int rows,cols,i,j 
#     cdef np.ndarray[np.float32_t, ndim=2] output=np.zeros([img.shape[0], img.shape[1]], dtype = np.float32)
#     # tamano de la imagen
#     rows = img.shape[0]
#     cols = img.shape[1]
#     #Como se van guardando los valores en la imagen integral, por construcci√≥n
#     #se puede realizar con 4 operaciones (usando valores precomputados), de esta
#     #manera se evita realizar sumas repetitivas.
# 
#     output[0][0] = img[0][0]
#     for i in range(rows):
#       for j in range(cols): 
#           #Casos base
#           if i==0:
#               output[i][j] = output[i][j-1] + img[i][j]
#           elif j==0:
#               output[i][j] = output[i-1][j] + img[i][j]
#           else:
#               output[i][j] = img[i][j]+output[i-1][j]+output[i][j-1]-output[i-1][j-1]
#         
#     return output

"""
3. Implementar una funci√≥n que genere par√°metros que permitan determinar las m√°scaras de
las caracter√≠sticas Haar. Las m√°scaras se deben parametrizar como: (y1, x1, y2, x2, tipo,
polaridad), donde:
a. (y1,x1) es la esquina superior izquierda de la m√°scara
b. (y2,x2) es la esquina inferior derecha de la m√°scara
c. Tipo: n√∫mero entre 0 y 4, que permite determinar el tipo de m√°scara
d. Polaridad: +1 (positiva) o ‚Äì1 (negativa).
Dado que en cada imagen las caracter√≠sticas de pueden calcular en muchas posibles
posiciones, se recomienda aplicarlas usando el concepto de ventana deslizante usando un
paso de tama√±o 3. Adem√°s, se recomienda usar s√≥lo 3 valores para los anchos de las
m√°scaras y 3 valores para los altos. En consecuencia, hay 9 posibles combinaciones de
anchos/altos. En el caso de las m√°scaras de tipo 0, 1 y 4, los anchos deben ser m√∫ltiplos de 4,
mientras que para las caracter√≠sticas 2 y 3, el ancho debe ser m√∫ltiplo de 3. Adem√°s, se debe
almacenar la polaridad de cada m√°scara, la cual puede ser +1 o -1.
"""
import numpy as np
def gen_parameters():
    L = []
    tipos = [   0,          1,      2,          3,      4]
    tipo2y3 = [3,6,9]
    anchos = [[4,8,12], [4,8,12], tipo2y3, tipo2y3,[4,8,12]]
    altos = [[4,8,12], [4,8,12], tipo2y3, tipo2y3,[4,8,12]]
    #generamos los parametros por cada tipo, sus 9 combinaciones
    #y adem√°s recorremos con una ventana deslizante de paso 3 con el fin
    #de determinar todas las mascaras que queden dentro de la imagen.
    for tipo in tipos:
            for y1 in range(0,24,3):
                for x1 in range(0,24,3):
                    for A in anchos[tipo]:
                        for B in altos[tipo]:
                            if y1+B<24 and x1+A<24:
                                #agregamos las mascaras en sus 2 polaridades
                                L.append([y1,x1,y1+B,x1+A,tipo,0])
                                L.append([y1,x1,y1+B,x1+A,tipo,1])

    return L


def Haar(img_set,mascaras):
    """
    4. Implementar una funci√≥n que, dado un conjunto de im√°genes y par√°metros de m√°scaras,
    calcule vectores de caracter√≠sticas. Dichos vectores deben contener todas las caracter√≠sticas
    tipo Haar determinadas en el punto anterior, para cada imagen.
    
    Por cada imagen, determinamos la imagen integral y luego dependiendo del tipo de la mascara
    se calcula el valor de la mascara aplicada en la imagen seg√∫n las posiciones que indica la mascara.
    """
    feature_set = []
    for img in img_set:
        features = np.zeros(len(mascaras))
        #determinamos la imagen integral
        I = integral(img)
        for index,mask in enumerate(mascaras):
            #rescatamos los parametros de la mascara
            y1,x1,y2,x2,tipo,p = mask
            A = x2-x1
            B = y2-y1
            
            if tipo==0:
                d = x1+A//2
                features[index]=p*(( I[y2][d]+I[y1][x1]-I[y2][x1]-I[y1][d] )       
                                -( I[y2][x2] + I[y1][d]-I[y2][d]-I[y1][x2]))
            elif tipo==1:
                d = y1+B//2
                features[index]=p*(( I[y2][x2]+I[d][x1]-I[y1][x2]-I[d][x2] )       
                                 -( I[d][x2] + I[y1][x1]-I[d][x1]-I[y1][x2]))
            elif tipo==2:
                d1 = x1+A//3
                d2 = x1+2*A//3
                features[index]=p*(  (I[y2][d1]+I[y1][x1]-I[y1][d1]-I[y2][x1])
                                    - ( I[y2][d2]+I[y1][d1]-I[y1][d2]-I[y2][d1])
                                    + ( I[y2][x2] + I[y1][d2] - I[y2][d2] - I[y1][x2]))
            elif tipo==3:
                d1 = y1+B//3
                d2 = y1+2*B//3
                features[index]=p*( (I[d1][x2] + I[y1][x1] - I[d1][x1] - I[y1][x2])
                                   -(I[d2][x2] + I[d1][x1] - I[d2][x1] - I[d1][x2])
                                   +(I[y2][x2] + I[d2][x1] - I[y2][x1] - I[d2][x2] ))
            else:
                dy = y1+B//2
                dx = x1+A//2
                features[index]=p*( (I[dy][dx] + I[y1][x1] - I[dy][x1] - I[y1][dx])
                                - (  I[dy][x2] + I[y1][dx] - I[dy][dx] - I[y1][x2])
                                - (  I[y2][dx] + I[dy][x1] - I[y2][x1] - I[dy][dx])
                                + (  I[y2][x2] + I[dy][dx] - I[y2][dx] - I[dy][x2]))
    
        feature_set.append(features)
    return np.array(feature_set)

parametros = gen_parameters()

X_train_features = Haar(X_train,parametros)
X_test_features = Haar(X_test,parametros)

X_train_features.shape

len(parametros)

"""
5.a. Implementar una funci√≥n ‚Ñé(ùë•, ùë¢), Su salida debe ser: +1 cuando ùë• > ùë¢ , -1 cuando
ùë• < ùë¢. En el caso en que x sea un arreglo, su salida debe tener la misma
dimensionalidad que x, y debe contener +1 o -1 en cada elemento. Esta funci√≥n se
usar√° como base para construir clasificadores d√©biles ‚Ñé(ùë•ùëñ, ùë¢) asociados a la caracter√≠stica n√∫mero i.
"""
def h(x,u):
    return (x>u)*2-1

"""b. Implementar una funci√≥n que permita elegir el mejor u para cada clasificador d√©bil,
dada una matriz de caracter√≠sticas X, un vector de etiquetas y, y un vector de pesos
w. Para realizar este paso, se debe dividir el rango de cada caracter√≠stica i en 10
valores, y se debe encontrar el valor de u en el cual el clasificador d√©bil asociado a
esa caracter√≠stica predice las etiquetas con el **mayor valor r**, donde

![image.png](data:image/png;base64,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)



con N el n√∫mero de ejemplos de entrenamiento, k el √≠ndice de estos ejemplos.

"""

def choose_u(X_feature,y_label,w_vec):
    """
    X_feauters corresponde a la caracteristica i, un vector 296.
    y_label vector de 296.
    """
    r = []
    U = []
    #cada columna representa una caracteristica, por cada columna determinamos
    #un valor de r
    for k in range(X_feature.shape[1]):
        r_list = []
        u_aux = []
        X_col = X_feature[:,k]
        inicio = np.min(X_col)
        fin =  np.max(X_col)
        #10 umbrales equidistantes entre el menor y el mayor valor
        u_list = np.linspace(inicio, fin, 10)
        for u in u_list:
            ri = np.sum(w_vec*y_label*h(X_col,u))
            r_list.append(ri)
            u_aux.append(u)
        U.append( u_aux[np.argmax(r_list)] )
        r.append(r_list[np.argmax(r_list)])
    return np.array(U),np.array(r)

def clasificador_fit(X_feature,y,T):
    #N muestras
    #inicializamos los pesos con 1/N
    at,it,ut,hf = [], [], [], []
    N = X_feature.shape[0]
    w = np.ones(N)*(1/N)

    for t in range(T):
        w = w/np.sum(w) #normalizamos los pesos
        u,r = choose_u(X_feature,y,w)
        alpha = 0.5*np.log((1+r)/(1-r))
        #indice del m√°ximo valor de r
        idxmax = np.argmax(r)
        rmax = np.max(r)
        at.append(0.5*np.log((1+rmax)/(1-rmax)))
        it.append(idxmax)
        ut.append(u[idxmax])

        #actualizamos los pesos
        w = w*np.exp(-alpha[idxmax]*y*h(X_feature[:,idxmax],u[idxmax]))

    return np.array(at),np.array(it),np.array(ut)

#Reuniendo todo en una clase Adaboost que representa al clasificador.
import numpy as np

class Adaboost:
    """
    Clasificador Adaboost, se genera a partir de clasificadores debiles.
    """
    def __init__(self):
        #iniciamos los arreglos que funcionaran como contenedores
        self.at = np.array([])
        self.it = np.array([])
        self.ut = np.array([])

    def h(x,u):
        return (x>u)*2-1

    def choose_u(X_feature,y_label,w_vec):
        """
        X_feauters corresponde a la caracteristica i, un vector 296.
        y_label vector de 296.
        """
        r = []
        U = []
        #cada columna representa una caracteristica, por cada columna determinamos
        #un valor de r
        for k in range(X_feature.shape[1]):
            r_list = []
            u_aux = []
            X_col = X_feature[:,k]
            inicio = np.min(X_col)
            fin =  np.max(X_col)
            #10 umbrales equidistantes entre el menor y el mayor valor
            u_list = np.linspace(inicio, fin, 10)
            for u in u_list:
                ri = np.sum(w_vec*y_label*h(X_col,u))
                r_list.append(ri)
                u_aux.append(u)
            U.append( u_aux[np.argmax(r_list)] )
            r.append(r_list[np.argmax(r_list)])
        return np.array(U),np.array(r)

    def fit(self,X_feature,y,T=10):
        #N muestras
        #inicializamos los pesos con 1/N
        at,it,ut,hf = [], [], [], []
        N = X_feature.shape[0]
        w = np.ones(N)*(1/N)
       
        for t in range(T):
            #w = w/np.sum(w) #normalizamos los pesos
            u,r = choose_u(X_feature,y,w)
            alpha = 0.5*np.log((1+r)/(1-r))
            #indice del m√°ximo valor de r
            idxmax = np.argmax(r)
            rmax = np.max(r)
            at.append(0.5*np.log((1+rmax)/(1-rmax)))
            it.append(idxmax)
            ut.append(u[idxmax])

            #actualizamos los pesos
            w = w*np.exp(-alpha[idxmax]*y*h(X_feature[:,idxmax],u[idxmax]))

        self.at = np.array(at)
        self.it = np.array(it)
        self.ut = np.array(ut)

    def predict(self,X):
        """
        x corresponde al vector de caracteristicas de una imagen o de un conjunto de imagenes
        a clasificar, at los alfas calculados, it los indices de los alfas calculados y ut los 
        umbrales respectivos.

        Predice la clase para las muestras en X.
        Parameters
        ----------
        X : The data matrix for which we want to get the predictions.
        El vector o matriz de caracteristicas 

        Returns
        -------
        y_pred : ndarray of shape (n_samples,)
            Vector que contiene las clases predichas para cada ejemplo.

        """
        try:
            y_pred = []
            for x in X:
                y_pred.append(np.sign(np.sum(self.at*h(x[self.it],self.ut))))
        except IndexError:
            y_pred = np.sign(np.sum(self.at*h(X[self.it],self.ut)))
        return np.array(y_pred)

clasificador = Adaboost() #inicializamos el clasificador
clasificador.fit(X_train_features,y_train,T=10)  #entrenamos
y_train_pred = clasificador.predict(X_train_features) #
y_test_pred = clasificador.predict(X_test_features)

# calculate accuracy
import matplotlib.pyplot as plt
from sklearn.metrics import  accuracy_score, confusion_matrix, recall_score
from sklearn.metrics import ConfusionMatrixDisplay

print("Train:")
accuracy = accuracy_score(y_train, y_train_pred)*100
recall = recall_score(y_train, y_train_pred, average='macro')*100
print("Classification accuracy is %2f"%accuracy,"%")
print("Classification recall is %2f"%recall,"%\n")

cm = confusion_matrix(y_train, y_train_pred,labels=[-1,1],normalize='true')
disp =ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=[-1,1])
disp.plot(cmap='Blues')
plt.title("Matriz de confusi√≥n normalizada\n del conjunto de entrenamiento T=10")
plt.show()

print("Test:")
accuracy = accuracy_score(y_test, y_test_pred)*100
recall = recall_score(y_test, y_test_pred, average='macro')*100
print("Classification accuracy is %2f"%accuracy,"%")
print("Classification recall is %2f"%recall,"%\n")

cm = confusion_matrix(y_test, y_test_pred,labels=[-1,1],normalize='true')
disp =ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=[-1,1])
disp.plot(cmap='Blues')
plt.title("Matriz de confusi√≥n normalizada\n del conjunto de test T=10")
plt.show()

import time
clasificador = Adaboost()

T = [5,10,20]
for t in T:
    inicio = time.time()
    clasificador.fit(X_train_features,y_train,T=t)
    y_train_pred = clasificador.predict(X_train_features)
    y_test_pred = clasificador.predict(X_test_features)
    final = time.time()
    print(f"Tiempo de ejecuci√≥n para T={t}: {round(final-inicio,2)} segundos.")

    print("Train:")
    accuracy = accuracy_score(y_train, y_train_pred)*100
    recall = recall_score(y_train, y_train_pred, average='macro')*100
    print("Classification accuracy is %2f"%accuracy,"%")
    print("Classification recall is %2f"%recall,"%\n")

    cm = confusion_matrix(y_train, y_train_pred,labels=[-1,1],normalize='true')
    disp =ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=[-1,1])
    disp.plot(cmap='Blues')
    plt.title(f"Matriz de confusi√≥n normalizada\n del conjunto de entrenamiento T={t}")
    plt.show()

    print("Test:")
    accuracy = accuracy_score(y_test, y_test_pred)*100
    recall = recall_score(y_test, y_test_pred, average='macro')*100
    print("Classification accuracy is %2f"%accuracy,"%")
    print("Classification recall is %2f"%recall,"%\n")

    cm = confusion_matrix(y_test, y_test_pred,labels=[-1,1],normalize='true')
    disp =ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=[-1,1])
    disp.plot(cmap='Blues')
    plt.title(f"Matriz de confusi√≥n normalizada\n del conjunto de test T={t}")
    plt.show()

clasificador = Adaboost() #inicializamos el clasificador
clasificador.fit(X_train_features,y_train,T=10)  #entrenamos
y_train_pred = clasificador.predict(X_train_features) #
y_test_pred = clasificador.predict(X_test_features)

p= np.array(parametros)
p[clasificador.it]

import cv2
from google.colab.patches import cv2_imshow

img = cv2.imread('/content/pedestrian/1.png')
image = cv2.resize(img, (192,192))
s=0
for y1,x1,y2,x2,tipo,polaridad in  p[clasificador.it]:
    if s<=6:    
        y1r = y1*192//24
        x1r = x1*192//24
        y2r = y2*192//24
        x2r = x2*192//24
        print(tipo,polaridad,(tipo*10,tipo*10,155+100*polaridad))
        #colores BGR
        image = cv2.rectangle(image, (x1r,y1r),(x2r,y2r),(int(60*(tipo)),int(10*(tipo)),int(150*polaridad+50*(1-tipo))),1)
    s+=1
cv2_imshow(image)

img = cv2.imread('/content/pedestrian/9.png')
image = cv2.resize(img, (192,192))
s=0
for y1,x1,y2,x2,tipo,polaridad in  p[clasificador.it]:
    if s<=6:    
        y1r = y1*192//24
        x1r = x1*192//24
        y2r = y2*192//24
        x2r = x2*192//24
        print(tipo,polaridad,(tipo*10,tipo*10,155+100*polaridad))
        image = cv2.rectangle(image, (x1r,y1r),(x2r,y2r),(int(60*(tipo)),int(10*(tipo)),int(150*polaridad+50*(1-tipo))),1)
    s+=1
cv2_imshow(image)

img = cv2.imread('/content/pedestrian/6.png')
image = cv2.resize(img, (192,192))
s=0
print(len(p[clasificador.it]))
for y1,x1,y2,x2,tipo,polaridad in  p[clasificador.it]:
    if s<=6:
        y1r = y1*192//24
        x1r = x1*192//24
        y2r = y2*192//24
        x2r = x2*192//24
        print(tipo,polaridad,(60*(tipo),10*(tipo),150*polaridad+50*(1-tipo)))
        image = cv2.rectangle(image, (x1r,y1r),(x2r,y2r),(int(60*(tipo)),int(10*(tipo)),int(150*polaridad+50*(1-tipo))),1)
    s+=1
cv2_imshow(image)